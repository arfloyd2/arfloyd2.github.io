Exploratory Data Analysis 

Before running a regression, conducting exploratory data analysis is vital to understanding and gaining insights on the data is provided to me. However, having a background understand is an essential part of building a founding for the EDA. Thus, before I do any type of EDA, I try to understand what the end goal of the analysis will be. For some projects, prediction and data insights such as optimization of results will be important, for others using the exploratory data analysis to possibly identify interesting patterns or inaccuracies in the data may be the main focus – so, speaking to stakeholders to see what kind information they are interested in obtaining would be the first step. Then, my job would be to provide that and any supporting information that will enhance and add value to the initial requests.  

Next, once I get an overview of what is being requested, doing and EDA will be an important step for me to gain an in in-depth introduction to the data. The first aspect, before pulling in the data is to look at the descriptions of the dataset overall and the variables provided. Doing so in the initial stages allows me to get an idea of what my response variable(s) would be and what trend and/or pattern structure do they take. Are they in the form of a time series where I’m looking at variables over time?  Are they discrete variables that are in the binary success/failure or 1/0 format, or are they counts of a variable recorded in a specific stretch of time? Is this continuous data which can take on any number on the real number line? What units of measurement are these response variables following? Getting an understanding for this type of information is important for forming a hypothesis on the structure of the response and creating a strategic process for conducting the actual EDA. Next, I would look at the descriptions of the explanatory variables. Is there a unique identifier in the records that distinguishes the observations. I try to spot any possible categorical variables that show how the data could be stratified or possibly adjusted to account for the different factor levels during the regression process. Finally, seeing which explanatory variables were recorded and how they relate (from a description standpoint) to the response would be an important insight that I look for.  

After getting an in-depth initial look at the descriptive portion of the data, now is time start interacting with the raw data itself. Before importing the data, it would be helpful to see how large the dataset is, so that I can try to foresee any possible run time issues during the computation phase, or to see if I may have to recycle the data if I do not have a large sample. After importing the data, I normally look to see if there is any initial data cleaning that might need to be done. Are there variables that might need to be renamed for ease of use, is there a variable that has multiple pieces of information in one column, and might need to parsed? Is there any missing data, and if there is missing data, is there any reason for the missing data other than the baseline reason of the record is just not available? When seeing missing data, it would be a good idea to contact the data providers to see if there are different reasons for why the data is missing, if the description doesn’t already provide the reasons. Is there code or indication within the data for why it is missing (for example, in some survey data missing data could mean that a participant has answered the question in an open-ended portion of the survey, or the question does not apply to them, or that they just were not comfortable answering the question.)?  Knowing the reasons could be important for reporting.  

Once the initial cleaning has been done, now I can work on the numerical and graphical analysis portion of the EDA. Having a solid handle on the descriptions of the variables will be helpful for this phase. By this time, I should know what the possible response variable(s) would be.  I would start the exploratory data analysis with numerical summaries. If there are categorial explanatory variables, what are the mean and variance values of the response for each category? I could extend this to obtaining the 5 number summary (minimum, 1st quartile, median, 3rd quartile, max) if that information would be valuable, otherwise, I could stay with the mean and variance. After getting the results, I would need to have enough background knowledge of the data to know whether or not the trends are expected (and therefore the data should probably be standardized, or adjusted to factor in these expected trends) or are they unusual and provide important information on their relationships with the response and should remain unadjusted. Speaking to subject matter experts would be helpful for reaching these conclusions. Next, it would be good to see if there are instances where I would need to know how many observations are in different factors of an explanatory variable. If that piece of insight would be useful, I would turn to contingency tables. Next, I would calculate a correlation matrix for all numerical variables in the data set. This helps to see if there is a correlation, or how strong the correlations are between the response and explanatory variables. This will also allow me to see if the explanatory variables are correlated with each other, and if so, how strong is the correlation- if there is a strong correlation, this would give me an idea that there may be multicollinearity that I would need to watch out for during the regression phase. 

Finally, once the numerical summaries have been conducted, I would do the graphical summaries. First If applicable, I would want to see the distribution of the response variable. If the variable is non-binary discrete or continuous, a histogram could give me an idea on which model might be a good fit for the regression/ modelling portion of the analysis, and could help me to identify skewness of the distribution, how wide the distribution spreads, and the kurtosis of the distribution.  After seeing the distribution of the response, I would probably try to create quantile – quantile plots that show how well the observed response does with the quantiles of randomly chosen values from a distribution that I think might fit the data well. After, I would create a scatter plot and possibly place a line of best fit to get a graphical view of the correlation strength between the response and explanatory variables of interest, and how well a linear regression with the untransformed variables could perform. Finally, a graphical illustration of the 5 number summary for the data (although this could be done at any time) would help me to see if there are outliers in the data. As I get more advanced in EDA, it might be helpful to see which of the outliers are influential to the regression, if it is optimal to keep them in the data set. 
